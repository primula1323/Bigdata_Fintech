{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "'''\n",
    "TODO\n",
    "1) addr_state 변수 설정해야한다\n",
    "2) 결측치에서 'acc_open_past_24mths', 'avg_cur_bal': 확인필요\n",
    "'''\n",
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.file_path = \"\"\n",
    "        self.folder_path = \"\"\n",
    "        self.df = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, data_file_path:str=\"\", folder_path:str=\"\"):\n",
    "        self.file_path = data_file_path\n",
    "        self.folder_path = folder_path\n",
    "        self.df = pd.DataFrame()\n",
    "        \n",
    "    def load_origin_file(self, file_path:str)->None:\n",
    "        if file_path!=\"\":\n",
    "            self.file_path = file_path\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "        \n",
    "    def drop_columns(self, drop_columns_file_path:str = \"drop_columns_0410.txt\")->None:\n",
    "        with open(drop_columns_file_path, mode='r') as f:\n",
    "            drop_fields = f.readlines()\n",
    "            drop_fields = [drop_field.strip('\\n') for drop_field in drop_fields]\n",
    "        self.df.drop(columns=drop_fields, inplace=True)\n",
    "    \n",
    "    def __preprocess_target_variable(self, target_variable:str=\"loan_status\")->None:\n",
    "        # loan_status가 \"current\", \"issued\", \"policy\" 인 행을 필터링하여 삭제\n",
    "        modified_df = self.df[~self.df[target_variable].isin(['Current', 'Issued', 'Does not meet the credit policy. Status:Fully Paid', 'Does not meet the credit policy. Status:Charged Off'])]\n",
    "        # risk = 1, safe = 0 으로 처리\n",
    "        modified_df.loc[modified_df['loan_status'].isin(['Fully Paid', 'In Grace Period']), 'loan_status'] = 0\n",
    "        modified_df.loc[modified_df['loan_status'].isin(['Charged Off', 'Default', 'Late (16-30 days)', 'Late (31-120 days)']), 'loan_status'] = 1\n",
    "        modified_df['loan_status'] = modified_df['loan_status'].astype('int')\n",
    "        self.df = modified_df\n",
    "        \n",
    "    ## 5. 데이터 처리용 함수\n",
    "    def __delete_suffix(self, term:str)->int:\n",
    "        '''첫 단어만을 저장하는 함수'''\n",
    "        term = term.strip().split()[0]\n",
    "        return int(term)\n",
    "\n",
    "    def __delete_suffix_percentage(self, term:str)->float:\n",
    "        '''%를 자르는 함수'''\n",
    "        term = term.strip('%')\n",
    "        return float(term)\n",
    "    \n",
    "    def __fill_na_with_value(self, columns:List[str], filling_value:Union[str, int])->None:\n",
    "        '''\n",
    "        df: dataframe to fill NA\n",
    "        column_name : column name to change NA values\n",
    "        filling_value : value type or just value to fill column's NA\n",
    "        '''\n",
    "        for column_name in columns:\n",
    "            if filling_value==\"mode\":\n",
    "                mode_value = self.df[column_name].mode()[0]\n",
    "            elif filling_value==\"median\":\n",
    "                mode_value = self.df[column_name].median()\n",
    "            else:\n",
    "                mode_value = filling_value\n",
    "            self.df[column_name].fillna(mode_value, inplace=True)\n",
    "        \n",
    "    def __preprocessing_na(self)->None:\n",
    "        '''\n",
    "        'acc_open_past_24mths', 확인필요\n",
    "        'avg_cur_bal', 확인필요\n",
    "        '''\n",
    "        ## 결측 처리\n",
    "        # 결측 개수가 1천 건 이하인 경우는 해당 데이터(row) 삭제\n",
    "        self.df.dropna(subset=['chargeoff_within_12_mths','collections_12_mths_ex_med','dti',\n",
    "                                                'pub_rec_bankruptcies','revol_util','tax_liens'], inplace=True)\n",
    "        \n",
    "        # A1. 최빈값 대체\n",
    "        self.__fill_na_with_value(columns=['mo_sin_old_il_acct', 'mths_since_recent_bc', 'mths_since_recent_inq', 'emp_length'], filling_value='mode')\n",
    "        \n",
    "        # A2. 중앙값 대체\n",
    "        self.__fill_na_with_value(columns=['bc_open_to_buy'], filling_value='median')\n",
    "        # B. 2015년 대체\n",
    "        # is_after_2015 컬럼 생성. all_util 변수를 기준으로 사용\n",
    "        self.df['is_after_2015'] = self.df['all_util'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "        # 결측값을 0으로 채우기\n",
    "        \n",
    "        # C. 2012년 대체\n",
    "        # is_after_2012 컬럼 생성. pct_tl_nvr_dlq 변수를 기준으로 사용\n",
    "        self.df['is_after_2012'] = self.df['pct_tl_nvr_dlq'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "        # D. 결측 0 대체\n",
    "        self.__fill_na_with_value(columns=['annual_inc_joint','dti_joint','revol_bal_joint', 'open_acc_6m',\n",
    "                                           'open_act_il', 'open_il_12m', 'open_il_24m', 'total_bal_il',\n",
    "                                           'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_cu_tl', 'mths_since_rcnt_il',\n",
    "                                           'tot_cur_bal', 'total_rev_hi_lim', 'mo_sin_old_rev_tl_op',\n",
    "                                           'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'num_bc_sats', 'num_bc_tl',\n",
    "                                           'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_il_tl',\n",
    "                                           'num_op_rev_tl','num_rev_accts','num_rev_tl_bal_gt_0','num_sats','num_tl_120dpd_2m','num_tl_30dpd',\n",
    "                                           'num_tl_90g_dpd_24m','num_tl_op_past_12m','pct_tl_nvr_dlq','tot_hi_cred_lim','total_bal_ex_mort',\n",
    "                                           'total_bc_limit','total_il_high_credit_limit'], filling_value=0)\n",
    "        \n",
    "        \n",
    "    def __convert_object_to_numeric(self, column_name:str)->pd.DataFrame:\n",
    "        unique_values = sorted(self.df[column_name].unique())\n",
    "        value_map = {value:index for index, value in enumerate(unique_values)}\n",
    "        self.df[column_name] = self.df[column_name].apply(lambda x:value_map.get(x))\n",
    "        return self.df\n",
    "    \n",
    "    def __convert_object_to_one_hot(self, column_name:str)->None:\n",
    "        encoded = pd.get_dummies(self.df[column_name])\n",
    "        self.df = pd.concat([self.df, encoded], axis=1)\n",
    "        self.df.drop(column_name, axis=1, inplace=True)\n",
    "        \n",
    "    def __preprocessing_objects(self)->None:\n",
    "        ## TODO : 'addr_state' 필드 해결하기\n",
    "        # term\n",
    "        self.df['term'] = self.df['term'].apply(self.__delete_suffix)\n",
    "        # emp_length\n",
    "        self.df['emp_length'] = self.df['emp_length'].apply(lambda x: x.replace(' years','').replace(' year','').replace('+','').replace('< 1', '0'))\n",
    "        self.df['emp_length'] = self.df['emp_length'].astype(int)\n",
    "        # revol_util\n",
    "        self.df['revol_util'] = self.df['revol_util'].apply(self.__delete_suffix_percentage)\n",
    "        \n",
    "        ## numeric\n",
    "        # application_type\n",
    "        self.df = self.__convert_object_to_numeric('application_type')\n",
    "        # sub_grade\n",
    "        self.df = self.__convert_object_to_numeric('sub_grade')\n",
    "\n",
    "        ## one-hot\n",
    "        # home_ownership\n",
    "        self.df['home_ownership'] = self.df['home_ownership'].replace(['ANY', 'OTHER', 'NONE'], 'OTHERS')\n",
    "        self.__convert_object_to_one_hot('home_ownership')\n",
    "        # purpose\n",
    "        self.__convert_object_to_one_hot('purpose')\n",
    "        # verification_status\n",
    "        self.__convert_object_to_one_hot('verification_status')\n",
    "        # addr_state : 해야함...\n",
    "\n",
    "    def preprocess(self)->None:\n",
    "        # loan_status 제외 모든 column이 결측치(na)인 행 제거 (1개 행 제거됨)\n",
    "        self.df.dropna(subset=self.df.columns.difference(['loan_status']),how='all', inplace=True)\n",
    "        self.__preprocess_target_variable()\n",
    "        # 결측치 제거\n",
    "        self.__preprocessing_na()\n",
    "        ## object 처리하기\n",
    "        self.__preprocessing_objects()\n",
    "        # index 재설정\n",
    "        self.df.reset_index(drop=True, inplace=True)\n",
    "        self.df.dropna(subset=self.df.columns.difference(['loan_status']),how='all', inplace=True)\n",
    "        \n",
    "    def get_df(self)->pd.DataFrame:\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocessor()\n",
    "# lending_club_2020_train.csv 파일이 있는 절대 경로 혹은 상대 경로를 명시해주세요\n",
    "p.load_origin_file(file_path=\"lending_club_2020_train.csv\")\n",
    "# drop_columns_0410.txt 파일의 위치를 명시해주세요\n",
    "p.drop_columns(drop_columns_file_path='drop_columns_0410.txt')\n",
    "# preprocess를 돌리면, addr_state를 제외한 object field 및, na(결측치) 처리됩니다.\n",
    "p.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acc_open_past_24mths', 'avg_cur_bal']\n"
     ]
    }
   ],
   "source": [
    "## 여기 뭔가가 이상함,,,\n",
    "df = p.get_df()\n",
    "columns_with_na = df.columns[df.isna().any()].tolist()\n",
    "print(columns_with_na)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래는 RFECV 관련 코드입니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df['loan_status']\n",
    "X_train = df.drop(columns=['addr_state', 'loan_status','acc_open_past_24mths', 'avg_cur_bal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 182948, number of negative: 722397\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.054146 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7412\n",
      "[LightGBM] [Info] Number of data points in the train set: 905345, number of used features: 88\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202075 -> initscore=-1.373373\n",
      "[LightGBM] [Info] Start training from score -1.373373\n",
      "[LightGBM] [Info] Number of positive: 182948, number of negative: 722397\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.046517 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7385\n",
      "[LightGBM] [Info] Number of data points in the train set: 905345, number of used features: 87\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202075 -> initscore=-1.373373\n",
      "[LightGBM] [Info] Start training from score -1.373373\n",
      "[LightGBM] [Info] Number of positive: 182948, number of negative: 722397\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044825 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7357\n",
      "[LightGBM] [Info] Number of data points in the train set: 905345, number of used features: 86\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202075 -> initscore=-1.373373\n",
      "[LightGBM] [Info] Start training from score -1.373373\n",
      "[LightGBM] [Info] Number of positive: 182948, number of negative: 722397\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.045775 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 7331\n",
      "[LightGBM] [Info] Number of data points in the train set: 905345, number of used features: 85\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.202075 -> initscore=-1.373373\n",
      "[LightGBM] [Info] Start training from score -1.373373\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 한 step에 제거할 featrue 개수 및 cross validation fold 수 지정\u001b[39;00m\n\u001b[1;32m      4\u001b[0m selector \u001b[38;5;241m=\u001b[39m RFECV(estimator, step\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, min_features_to_select\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m selector \u001b[38;5;241m=\u001b[39m selector\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:725\u001b[0m, in \u001b[0;36mRFECV.fit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    722\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    723\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[0;32m--> 725\u001b[0m scores \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    726\u001b[0m     func(rfe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y, train, test, scorer)\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    728\u001b[0m )\n\u001b[1;32m    730\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[1;32m    731\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:726\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    722\u001b[0m     parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n\u001b[1;32m    723\u001b[0m     func \u001b[38;5;241m=\u001b[39m delayed(_rfe_single_fit)\n\u001b[1;32m    725\u001b[0m scores \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m--> 726\u001b[0m     func(rfe, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator, X, y, train, test, scorer)\n\u001b[1;32m    727\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups)\n\u001b[1;32m    728\u001b[0m )\n\u001b[1;32m    730\u001b[0m scores \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(scores)\n\u001b[1;32m    731\u001b[0m scores_sum \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(scores, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:37\u001b[0m, in \u001b[0;36m_rfe_single_fit\u001b[0;34m(rfe, estimator, X, y, train, test, scorer)\u001b[0m\n\u001b[1;32m     35\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, train)\n\u001b[1;32m     36\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m _safe_split(estimator, X, y, test, train)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rfe\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[1;32m     38\u001b[0m     X_train,\n\u001b[1;32m     39\u001b[0m     y_train,\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m estimator, features: _score(\n\u001b[1;32m     41\u001b[0m         estimator, X_test[:, features], y_test, scorer\n\u001b[1;32m     42\u001b[0m     ),\n\u001b[1;32m     43\u001b[0m )\u001b[38;5;241m.\u001b[39mscores_\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/feature_selection/_rfe.py:299\u001b[0m, in \u001b[0;36mRFE._fit\u001b[0;34m(self, X, y, step_score, **fit_params)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m features.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m np\u001b[38;5;241m.\u001b[39msum(support_))\n\u001b[0;32m--> 299\u001b[0m estimator\u001b[38;5;241m.\u001b[39mfit(X[:, features], y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[1;32m    302\u001b[0m importances \u001b[38;5;241m=\u001b[39m _get_feature_importances(\n\u001b[1;32m    303\u001b[0m     estimator,\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimportance_getter,\n\u001b[1;32m    305\u001b[0m     transform_func\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msquare\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    306\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/lightgbm/sklearn.py:1187\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1185\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[0;32m-> 1187\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m   1188\u001b[0m     X,\n\u001b[1;32m   1189\u001b[0m     _y,\n\u001b[1;32m   1190\u001b[0m     sample_weight\u001b[38;5;241m=\u001b[39msample_weight,\n\u001b[1;32m   1191\u001b[0m     init_score\u001b[38;5;241m=\u001b[39minit_score,\n\u001b[1;32m   1192\u001b[0m     eval_set\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m   1193\u001b[0m     eval_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m   1194\u001b[0m     eval_sample_weight\u001b[38;5;241m=\u001b[39meval_sample_weight,\n\u001b[1;32m   1195\u001b[0m     eval_class_weight\u001b[38;5;241m=\u001b[39meval_class_weight,\n\u001b[1;32m   1196\u001b[0m     eval_init_score\u001b[38;5;241m=\u001b[39meval_init_score,\n\u001b[1;32m   1197\u001b[0m     eval_metric\u001b[38;5;241m=\u001b[39meval_metric,\n\u001b[1;32m   1198\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[1;32m   1199\u001b[0m     categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_feature,\n\u001b[1;32m   1200\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m   1201\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model\n\u001b[1;32m   1202\u001b[0m )\n\u001b[1;32m   1203\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/lightgbm/sklearn.py:885\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[1;32m    882\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    883\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[0;32m--> 885\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[1;32m    886\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    887\u001b[0m     train_set\u001b[38;5;241m=\u001b[39mtrain_set,\n\u001b[1;32m    888\u001b[0m     num_boost_round\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators,\n\u001b[1;32m    889\u001b[0m     valid_sets\u001b[38;5;241m=\u001b[39mvalid_sets,\n\u001b[1;32m    890\u001b[0m     valid_names\u001b[38;5;241m=\u001b[39meval_names,\n\u001b[1;32m    891\u001b[0m     feval\u001b[38;5;241m=\u001b[39meval_metrics_callable,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     init_model\u001b[38;5;241m=\u001b[39minit_model,\n\u001b[1;32m    893\u001b[0m     feature_name\u001b[38;5;241m=\u001b[39mfeature_name,\n\u001b[1;32m    894\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks\n\u001b[1;32m    895\u001b[0m )\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evals_result \u001b[38;5;241m=\u001b[39m evals_result\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_best_iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mbest_iteration\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/lightgbm/engine.py:276\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, feature_name, categorical_feature, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[1;32m    269\u001b[0m     cb(callback\u001b[38;5;241m.\u001b[39mCallbackEnv(model\u001b[38;5;241m=\u001b[39mbooster,\n\u001b[1;32m    270\u001b[0m                             params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    271\u001b[0m                             iteration\u001b[38;5;241m=\u001b[39mi,\n\u001b[1;32m    272\u001b[0m                             begin_iteration\u001b[38;5;241m=\u001b[39minit_iteration,\n\u001b[1;32m    273\u001b[0m                             end_iteration\u001b[38;5;241m=\u001b[39minit_iteration \u001b[38;5;241m+\u001b[39m num_boost_round,\n\u001b[1;32m    274\u001b[0m                             evaluation_result_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 276\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(fobj\u001b[38;5;241m=\u001b[39mfobj)\n\u001b[1;32m    278\u001b[0m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    279\u001b[0m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/lightgbm/basic.py:3891\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, train_set, fobj)\u001b[0m\n\u001b[1;32m   3889\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__set_objective_to_none:\n\u001b[1;32m   3890\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot update due to null objective function.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 3891\u001b[0m _safe_call(_LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterUpdateOneIter(\n\u001b[1;32m   3892\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m   3893\u001b[0m     ctypes\u001b[38;5;241m.\u001b[39mbyref(is_finished)))\n\u001b[1;32m   3894\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__is_predicted_cur_iter \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__num_dataset)]\n\u001b[1;32m   3895\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 학습시킬 모델 지정\n",
    "#estimator = LGBMClassifier(random_state=1111, n_estimators=100, learning_rate=0.01)\n",
    "# 한 step에 제거할 featrue 개수 및 cross validation fold 수 지정\n",
    "#selector = RFECV(estimator, step=1, cv = 5, min_features_to_select=20)\n",
    "#selector = selector.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RFECV' object has no attribute 'support_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m selected_columns \u001b[38;5;241m=\u001b[39m X_train\u001b[38;5;241m.\u001b[39mcolumns[selector\u001b[38;5;241m.\u001b[39msupport_]\n\u001b[1;32m      2\u001b[0m selected_columns\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RFECV' object has no attribute 'support_'"
     ]
    }
   ],
   "source": [
    "#selected_columns = X_train.columns[selector.support_]\n",
    "#selected_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RFECV' object has no attribute 'support_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_train_selected \u001b[38;5;241m=\u001b[39m X_train[X_train\u001b[38;5;241m.\u001b[39mcolumns[selector\u001b[38;5;241m.\u001b[39msupport_]]\n\u001b[1;32m      2\u001b[0m y_train\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'RFECV' object has no attribute 'support_'"
     ]
    }
   ],
   "source": [
    "#X_train_selected = X_train[X_train.columns[selector.support_]]\n",
    "#y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train[['loan_amnt', 'term', 'sub_grade', 'annual_inc', 'dti', 'fico_range_low',\n",
    "       'revol_bal', 'tot_cur_bal', 'open_rv_24m', 'max_bal_bc',\n",
    "       'mo_sin_old_rev_tl_op', 'mort_acc', 'mths_since_recent_bc',\n",
    "       'num_actv_rev_tl', 'num_tl_op_past_12m', 'tot_hi_cred_lim',\n",
    "       'revol_bal_joint', 'is_after_2015', 'MORTGAGE', 'RENT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train_selected, y_train)\n",
    "SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_selected = X_train[['loan_amnt', 'term', 'sub_grade', 'annual_inc', 'dti', 'fico_range_low',\n",
    "       'revol_bal', 'tot_cur_bal', 'open_rv_24m', 'max_bal_bc',\n",
    "       'mo_sin_old_rev_tl_op', 'mort_acc', 'mths_since_recent_bc',\n",
    "       'num_actv_rev_tl', 'num_tl_op_past_12m', 'tot_hi_cred_lim',\n",
    "       'revol_bal_joint', 'is_after_2015', 'MORTGAGE', 'RENT']]\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ISLP import confusion_table\n",
    "import pygam\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "X_train_selected, y_train\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X_train, y_train, test_size = 0.3, random_state = 1111)#X_train_Selected로 바꿀 수도 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.89    270805\n",
      "           1       0.57      0.03      0.06     68700\n",
      "\n",
      "    accuracy                           0.80    339505\n",
      "   macro avg       0.69      0.51      0.47    339505\n",
      "weighted avg       0.76      0.80      0.72    339505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>269181</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66510</td>\n",
       "      <td>2190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth           0     1\n",
       "Predicted              \n",
       "0          269181  1624\n",
       "1           66510  2190"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "clf = RidgeClassifier().fit(X_tr, y_tr)\n",
    "clf.score(X_te, y_te)\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(classification_report(y_te, y_pred))\n",
    "confusion_table(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.83      0.83    270805\n",
      "           1       0.31      0.30      0.31     68700\n",
      "\n",
      "    accuracy                           0.72    339505\n",
      "   macro avg       0.57      0.57      0.57    339505\n",
      "weighted avg       0.72      0.72      0.72    339505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>224358</td>\n",
       "      <td>46447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47955</td>\n",
       "      <td>20745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth           0      1\n",
       "Predicted               \n",
       "0          224358  46447\n",
       "1           47955  20745"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf = QuadraticDiscriminantAnalysis().fit(X_tr, y_tr)\n",
    "clf.score(X_te, y_te)\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(classification_report(y_te, y_pred))\n",
    "confusion_table(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8936657781181426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.73      0.78    270805\n",
      "           1       0.30      0.46      0.37     68700\n",
      "\n",
      "    accuracy                           0.68    339505\n",
      "   macro avg       0.57      0.60      0.58    339505\n",
      "weighted avg       0.73      0.68      0.70    339505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>199001</td>\n",
       "      <td>71804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37211</td>\n",
       "      <td>31489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth           0      1\n",
       "Predicted               \n",
       "0          199001  71804\n",
       "1           37211  31489"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (clf.predict_proba(X_te)[:,1] >= 0.2).astype(bool)\n",
    "print(clf.score(X_te, y_pred))\n",
    "print(classification_report(y_te, y_pred))\n",
    "confusion_table(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    270805\n",
      "           1       0.51      0.10      0.16     68700\n",
      "\n",
      "    accuracy                           0.80    339505\n",
      "   macro avg       0.66      0.54      0.52    339505\n",
      "weighted avg       0.75      0.80      0.74    339505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis().fit(X_tr, y_tr)\n",
    "clf.score(X_te, y_te)\n",
    "\n",
    "y_pred = clf.predict(X_te)\n",
    "print(classification_report(y_te, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6425708016082238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.67      0.76    270805\n",
      "           1       0.33      0.64      0.43     68700\n",
      "\n",
      "    accuracy                           0.66    339505\n",
      "   macro avg       0.60      0.65      0.59    339505\n",
      "weighted avg       0.77      0.66      0.69    339505\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Truth</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>180283</td>\n",
       "      <td>90522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25021</td>\n",
       "      <td>43679</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Truth           0      1\n",
       "Predicted               \n",
       "0          180283  90522\n",
       "1           25021  43679"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LDA\n",
    "y_pred = (clf.predict_proba(X_te)[:,1] >= 0.2).astype(bool)\n",
    "print(clf.score(X_te, y_pred))\n",
    "print(classification_report(y_te, y_pred))\n",
    "confusion_table(y_te, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.95      0.87    270805\n",
      "           1       0.40      0.13      0.20     68700\n",
      "\n",
      "    accuracy                           0.78    339505\n",
      "   macro avg       0.60      0.54      0.54    339505\n",
      "weighted avg       0.73      0.78      0.74    339505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB().fit(X_tr, y_tr)\n",
    "y_pred = clf.predict(X_te)\n",
    "print(classification_report(y_te, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8096552333544424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.81    270805\n",
      "           1       0.34      0.43      0.38     68700\n",
      "\n",
      "    accuracy                           0.72    339505\n",
      "   macro avg       0.59      0.61      0.60    339505\n",
      "weighted avg       0.74      0.72      0.73    339505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = (clf.predict_proba(X_te)[:,1] >= 0.2).astype(bool)\n",
    "print(clf.score(X_te, y_pred))\n",
    "print(classification_report(y_te, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import scipy\n",
    "from pygam import LogisticGAM, s, f, te\n",
    "\n",
    "gam = LogisticGAM(s(0, n_splines=200) + te(3, 1) + s(2)).fit(X_te, y_te)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gam.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.svm import l1_min_c\n",
    "\n",
    "cs = l1_min_c(X_train_selected, y_train, loss=\"log\") * np.logspace(0, 10, 16)\n",
    "\n",
    "clf = linear_model.LogisticRegression(\n",
    "    penalty=\"l1\",\n",
    "    solver=\"liblinear\",\n",
    "    tol=1e-6,\n",
    "    max_iter=int(1e6),\n",
    "    warm_start=True,\n",
    "    intercept_scaling=10000.0,\n",
    ")\n",
    "coefs_ = []\n",
    "for c in cs:\n",
    "    clf.set_params(C=c)\n",
    "    clf.fit(X_train_selected, y_train)\n",
    "    coefs_.append(clf.coef_.ravel().copy())\n",
    "\n",
    "coefs_ = np.array(coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
