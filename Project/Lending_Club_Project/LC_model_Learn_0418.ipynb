{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from typing import Union, List\n",
    "#import ISLP\n",
    "\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        self.file_path = \"\"\n",
    "        self.folder_path = \"\"\n",
    "        self.df = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, data_file_path:str=\"\", folder_path:str=\"\"):\n",
    "        self.file_path = data_file_path\n",
    "        self.folder_path = folder_path\n",
    "        self.df = pd.DataFrame()\n",
    "        \n",
    "    def load_origin_file(self, file_path:str)->None:\n",
    "        if file_path!=\"\":\n",
    "            self.file_path = file_path\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "        \n",
    "    def drop_columns(self, drop_columns_file_path:str = \"drop_columns_0410.txt\")->None:\n",
    "        with open(drop_columns_file_path, mode='r') as f:\n",
    "            drop_fields = f.readlines()\n",
    "            drop_fields = [drop_field.strip('\\n') for drop_field in drop_fields]\n",
    "        self.df.drop(columns=drop_fields, inplace=True)\n",
    "    \n",
    "    def __preprocess_target_variable(self, target_variable:str=\"loan_status\")->None:\n",
    "        # loan_status가 \"current\", \"issued\", \"policy\" 인 행을 필터링하여 삭제\n",
    "        modified_df = self.df[~self.df[target_variable].isin(['Current', 'Issued', 'Does not meet the credit policy. Status:Fully Paid', 'Does not meet the credit policy. Status:Charged Off'])]\n",
    "        # risk = 1, safe = 0 으로 처리\n",
    "        modified_df.loc[modified_df['loan_status'].isin(['Fully Paid', 'In Grace Period']), 'loan_status'] = 0\n",
    "        modified_df.loc[modified_df['loan_status'].isin(['Charged Off', 'Default', 'Late (16-30 days)', 'Late (31-120 days)']), 'loan_status'] = 1\n",
    "        modified_df['loan_status'] = modified_df['loan_status'].astype('int')\n",
    "        self.df = modified_df\n",
    "        \n",
    "    ## 5. 데이터 처리용 함수\n",
    "    def __delete_suffix(self, term:str)->int:\n",
    "        '''첫 단어만을 저장하는 함수'''\n",
    "        term = term.strip().split()[0]\n",
    "        return int(term)\n",
    "\n",
    "    def __delete_suffix_percentage(self, term:str)->float:\n",
    "        '''%를 자르는 함수'''\n",
    "        term = term.strip('%')\n",
    "        return float(term)\n",
    "    \n",
    "    def __fill_na_with_value(self, columns:List[str], filling_value:Union[str, int])->None:\n",
    "        '''\n",
    "        df: dataframe to fill NA\n",
    "        column_name : column name to change NA values\n",
    "        filling_value : value type or just value to fill column's NA\n",
    "        '''\n",
    "        for column_name in columns:\n",
    "            if filling_value==\"mode\":\n",
    "                mode_value = self.df[column_name].mode()[0]\n",
    "            elif filling_value==\"median\":\n",
    "                mode_value = self.df[column_name].median()\n",
    "            else:\n",
    "                mode_value = filling_value\n",
    "            self.df[column_name].fillna(mode_value, inplace=True)\n",
    "        \n",
    "    def __preprocessing_na(self)->None:\n",
    "        '''\n",
    "        'acc_open_past_24mths', 확인필요\n",
    "        'avg_cur_bal', 확인필요\n",
    "        '''\n",
    "        ## 결측 처리\n",
    "        # 결측 개수가 1천 건 이하인 경우는 해당 데이터(row) 삭제\n",
    "        self.df.dropna(subset=['chargeoff_within_12_mths','collections_12_mths_ex_med','dti',\n",
    "                                                'pub_rec_bankruptcies','revol_util','tax_liens'], inplace=True)\n",
    "        \n",
    "        # A1. 최빈값 대체\n",
    "        self.__fill_na_with_value(columns=['mo_sin_old_il_acct', 'mths_since_recent_bc', 'mths_since_recent_inq', 'emp_length'], filling_value='mode')\n",
    "        \n",
    "        # A2. 중앙값 대체\n",
    "        self.__fill_na_with_value(columns=['bc_open_to_buy'], filling_value='median')\n",
    "        # B. 2015년 대체\n",
    "        # is_after_2015 컬럼 생성. all_util 변수를 기준으로 사용\n",
    "        self.df['is_after_2015'] = self.df['all_util'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "        # 결측값을 0으로 채우기\n",
    "        \n",
    "        # C. 2012년 대체\n",
    "        # is_after_2012 컬럼 생성. pct_tl_nvr_dlq 변수를 기준으로 사용\n",
    "        self.df['is_after_2012'] = self.df['pct_tl_nvr_dlq'].apply(lambda x: 0 if pd.isnull(x) else 1)\n",
    "        # D. 결측 0 대체\n",
    "        self.__fill_na_with_value(columns=['annual_inc_joint','dti_joint','revol_bal_joint', 'open_acc_6m',\n",
    "                                           'open_act_il', 'open_il_12m', 'open_il_24m', 'total_bal_il',\n",
    "                                           'open_rv_12m', 'open_rv_24m', 'max_bal_bc', 'all_util', 'total_cu_tl', 'mths_since_rcnt_il',\n",
    "                                           'tot_cur_bal', 'total_rev_hi_lim', 'mo_sin_old_rev_tl_op',\n",
    "                                           'mo_sin_rcnt_rev_tl_op', 'mo_sin_rcnt_tl', 'mort_acc', 'num_bc_sats', 'num_bc_tl',\n",
    "                                           'num_accts_ever_120_pd', 'num_actv_bc_tl', 'num_actv_rev_tl', 'num_il_tl',\n",
    "                                           'num_op_rev_tl','num_rev_accts','num_rev_tl_bal_gt_0','num_sats','num_tl_120dpd_2m','num_tl_30dpd',\n",
    "                                           'num_tl_90g_dpd_24m','num_tl_op_past_12m','pct_tl_nvr_dlq','tot_hi_cred_lim','total_bal_ex_mort',\n",
    "                                           'total_bc_limit','total_il_high_credit_limit'], filling_value=0)\n",
    "        \n",
    "        \n",
    "    def __convert_object_to_numeric(self, column_name:str)->pd.DataFrame:\n",
    "        unique_values = sorted(self.df[column_name].unique())\n",
    "        value_map = {value:index for index, value in enumerate(unique_values)}\n",
    "        self.df[column_name] = self.df[column_name].apply(lambda x:value_map.get(x))\n",
    "        return self.df\n",
    "    \n",
    "    def __convert_object_to_one_hot(self, column_name:str)->None:\n",
    "        encoded = pd.get_dummies(self.df[column_name])\n",
    "        self.df = pd.concat([self.df, encoded], axis=1)\n",
    "        self.df.drop(column_name, axis=1, inplace=True)\n",
    "        \n",
    "    def __preprocessing_objects(self)->None:\n",
    "        ## TODO : 'addr_state' 필드 해결하기\n",
    "        # term\n",
    "        self.df['term'] = self.df['term'].apply(self.__delete_suffix)\n",
    "        # emp_length\n",
    "        self.df['emp_length'] = self.df['emp_length'].apply(lambda x: x.replace(' years','').replace(' year','').replace('+','').replace('< 1', '0'))\n",
    "        self.df['emp_length'] = self.df['emp_length'].astype(int)\n",
    "        # revol_util\n",
    "        self.df['revol_util'] = self.df['revol_util'].apply(self.__delete_suffix_percentage)\n",
    "        \n",
    "        ## numeric\n",
    "        # application_type\n",
    "        self.df = self.__convert_object_to_numeric('application_type')\n",
    "        # sub_grade\n",
    "        self.df = self.__convert_object_to_numeric('sub_grade')\n",
    "\n",
    "        ## one-hot\n",
    "        # home_ownership\n",
    "        self.df['home_ownership'] = self.df['home_ownership'].replace(['ANY', 'OTHER', 'NONE'], 'OTHERS')\n",
    "        self.__convert_object_to_one_hot('home_ownership')\n",
    "        # purpose\n",
    "        self.__convert_object_to_one_hot('purpose')\n",
    "        # verification_status\n",
    "        self.__convert_object_to_one_hot('verification_status')\n",
    "        # addr_state : 해야함...\n",
    "\n",
    "    def preprocess(self)->None:\n",
    "        # loan_status 제외 모든 column이 결측치(na)인 행 제거 (1개 행 제거됨)\n",
    "        self.df.dropna(subset=self.df.columns.difference(['loan_status']),how='all', inplace=True)\n",
    "        self.__preprocess_target_variable()\n",
    "        # 결측치 제거\n",
    "        self.__preprocessing_na()\n",
    "        ## object 처리하기\n",
    "        self.__preprocessing_objects()\n",
    "        # index 재설정\n",
    "        self.df.reset_index(drop=True, inplace=True)\n",
    "        self.df.dropna(subset=self.df.columns.difference(['loan_status']),how='all', inplace=True)\n",
    "        \n",
    "    def get_df(self)->pd.DataFrame:\n",
    "        return self.df\n",
    "\n",
    "\n",
    "p = Preprocessor()\n",
    "p.load_origin_file(file_path=\"lending_club_2020_train.csv\")\n",
    "p.drop_columns(drop_columns_file_path='drop_columns_0410.txt')\n",
    "p.preprocess()\n",
    "df = p.get_df()\n",
    "columns_with_na = df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['addr_state','acc_open_past_24mths', 'avg_cur_bal'])\n",
    "X = df.drop(columns=['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, df['loan_status'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.52      0.64    180516\n",
      "           1       0.24      0.60      0.34     45821\n",
      "\n",
      "    accuracy                           0.54    226337\n",
      "   macro avg       0.54      0.56      0.49    226337\n",
      "weighted avg       0.72      0.54      0.58    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "clf = RidgeClassifierCV().fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89    180516\n",
      "           1       0.37      0.00      0.00     45821\n",
      "\n",
      "    accuracy                           0.80    226337\n",
      "   macro avg       0.58      0.50      0.44    226337\n",
      "weighted avg       0.71      0.80      0.71    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "clf = LogisticRegressionCV(penalty='l1', solver = 'saga').fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "#48분 걸려서 recall 0!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA, QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    180516\n",
      "           1       0.51      0.10      0.16     45821\n",
      "\n",
      "    accuracy                           0.80    226337\n",
      "   macro avg       0.66      0.54      0.52    226337\n",
      "weighted avg       0.75      0.80      0.74    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#LDA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "clf = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77    180516\n",
      "           1       0.30      0.52      0.38     45821\n",
      "\n",
      "    accuracy                           0.66    226337\n",
      "   macro avg       0.58      0.61      0.57    226337\n",
      "weighted avg       0.74      0.66      0.69    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# QDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clf = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.81      0.82    180516\n",
      "           1       0.35      0.41      0.37     45821\n",
      "\n",
      "    accuracy                           0.73    226337\n",
      "   macro avg       0.59      0.61      0.60    226337\n",
      "weighted avg       0.74      0.73      0.73    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB().fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m코드를 실행할 수 없습니다. 세션이 삭제되었습니다. 커널을 다시 시작해 보세요."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m코드를 실행할 수 없습니다. 세션이 삭제되었습니다. 커널을 다시 시작해 보세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
