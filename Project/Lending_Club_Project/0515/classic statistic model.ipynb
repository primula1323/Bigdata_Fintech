{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from collections import Counter\n",
    "from typing import Union, List\n",
    "import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('scaled_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat_OTHERS', 'cat_OWN', 'cat_RENT', 'cat_credit_card',\n",
       "       'cat_debt_consolidation', 'cat_educational', 'cat_home_improvement',\n",
       "       'cat_house', 'cat_major_purchase', 'cat_medical', 'cat_moving',\n",
       "       'cat_other', 'cat_renewable_energy', 'cat_small_business',\n",
       "       'cat_vacation', 'cat_wedding', 'loan_amnt', 'term', 'int_rate',\n",
       "       'installment', 'sub_grade', 'emp_length', 'verification_status',\n",
       "       'delinq_2yrs', 'inq_last_6mths', 'pub_rec', 'revol_util',\n",
       "       'collections_12_mths_ex_med', 'application_type', 'dti_joint',\n",
       "       'acc_now_delinq', 'chargeoff_within_12_mths', 'mths_since_recent_inq',\n",
       "       'num_tl_120dpd_2m', 'num_tl_30dpd', 'num_tl_90g_dpd_24m',\n",
       "       'num_tl_op_past_12m', 'pct_tl_nvr_dlq', 'is_after_2015',\n",
       "       'is_after_2012', 'fico_avg', 'all_util_log', 'annual_inc_log',\n",
       "       'annual_inc_joint_log', 'bc_open_to_buy_log', 'delinq_amnt_log',\n",
       "       'dti_log', 'max_bal_bc_log', 'mo_sin_old_il_acct_log',\n",
       "       'mo_sin_old_rev_tl_op_log', 'mo_sin_rcnt_rev_tl_op_log',\n",
       "       'mo_sin_rcnt_tl_log', 'mort_acc_log', 'mths_since_rcnt_il_log',\n",
       "       'mths_since_recent_bc_log', 'num_accts_ever_120_pd_log',\n",
       "       'num_actv_bc_tl_log', 'num_actv_rev_tl_log', 'num_bc_sats_log',\n",
       "       'num_bc_tl_log', 'num_il_tl_log', 'num_op_rev_tl_log',\n",
       "       'num_rev_accts_log', 'num_rev_tl_bal_gt_0_log', 'num_sats_log',\n",
       "       'open_acc_log', 'open_acc_6m_log', 'open_act_il_log', 'open_il_12m_log',\n",
       "       'open_il_24m_log', 'open_rv_12m_log', 'open_rv_24m_log',\n",
       "       'pub_rec_bankruptcies_log', 'revol_bal_log', 'revol_bal_joint_log',\n",
       "       'tax_liens_log', 'tot_cur_bal_log', 'tot_hi_cred_lim_log',\n",
       "       'total_acc_log', 'total_bal_ex_mort_log', 'total_bal_il_log',\n",
       "       'total_bc_limit_log', 'total_cu_tl_log',\n",
       "       'total_il_high_credit_limit_log', 'total_rev_hi_lim_log', 'loan_status',\n",
       "       'raw_loan_amnt', 'raw_total_pymnt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131682, 88)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df_y = df['loan_status']\n",
    "df_X = df.drop(columns=['loan_status', 'raw_total_pymnt', 'raw_loan_amnt'])\n",
    "origin_train_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_custom_roe(df):\n",
    "    equity, returns = 0, 0\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i]['y_pred'] == 0:   \n",
    "            equity += df.iloc[i]['raw_loan_amnt']\n",
    "            returns += df.iloc[i]['raw_total_pymnt']\n",
    "        else:\n",
    "            equity += df.iloc[i]['raw_loan_amnt']\n",
    "            returns += df.iloc[i]['raw_loan_amnt'] * 1.03\n",
    "    return returns / equity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Lasso penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82    180600\n",
      "           1       0.35      0.46      0.40     45737\n",
      "\n",
      "    accuracy                           0.72    226337\n",
      "   macro avg       0.60      0.62      0.61    226337\n",
      "weighted avg       0.75      0.72      0.73    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82    180600\n",
      "           1       0.35      0.46      0.40     45737\n",
      "\n",
      "    accuracy                           0.72    226337\n",
      "   macro avg       0.60      0.62      0.61    226337\n",
      "weighted avg       0.75      0.72      0.73    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82    180599\n",
      "           1       0.35      0.46      0.40     45737\n",
      "\n",
      "    accuracy                           0.72    226336\n",
      "   macro avg       0.60      0.62      0.61    226336\n",
      "weighted avg       0.75      0.72      0.73    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82    180599\n",
      "           1       0.35      0.46      0.40     45737\n",
      "\n",
      "    accuracy                           0.72    226336\n",
      "   macro avg       0.60      0.62      0.61    226336\n",
      "weighted avg       0.75      0.72      0.73    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.78      0.82    180599\n",
      "           1       0.35      0.46      0.40     45737\n",
      "\n",
      "    accuracy                           0.72    226336\n",
      "   macro avg       0.60      0.62      0.61    226336\n",
      "weighted avg       0.75      0.72      0.73    226336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(shuffle=True, random_state=30)\n",
    "roelst_Lasso = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_X, df_y)):\n",
    "    # 인덱스를 사용하여 학습 및 테스트 데이터를 추출\n",
    "    X_train_fold = df_X.iloc[train_index]\n",
    "    y_train_fold = df_y.iloc[train_index]\n",
    "    X_test_fold = df_X.iloc[test_index]\n",
    "    y_test_fold = df_y.iloc[test_index]\n",
    "\n",
    "    # SMOTE 오버샘플링\n",
    "    smote = SMOTE(random_state=30)\n",
    "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # RidgeClassifierCV 학습\n",
    "    clfLasso_fold = LogisticRegressionCV(random_state = 30, solver = 'saga').fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Test Error:')\n",
    "    y_pred = clfLasso_fold.predict(X_test_fold)\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "\n",
    "    origin_test_df = df.iloc[test_index]\n",
    "\n",
    "    # ROE 계산 및 추가\n",
    "    origin_test_df['y_pred'] = y_pred\n",
    "    roelst_Lasso.append(my_custom_roe(origin_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0447910683448645, 1.0442785382641457, 1.0450904476982943, 1.0451302780769849, 1.0452042055905486]\n",
      "1.0448989075949675\n"
     ]
    }
   ],
   "source": [
    "print(roelst_Lasso)\n",
    "ROE_Lasso = np.mean(roelst_Lasso)\n",
    "print(ROE_Lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression - Ridge penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82    180600\n",
      "           1       0.36      0.45      0.40     45737\n",
      "\n",
      "    accuracy                           0.73    226337\n",
      "   macro avg       0.60      0.62      0.61    226337\n",
      "weighted avg       0.75      0.73      0.74    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82    180600\n",
      "           1       0.36      0.44      0.39     45737\n",
      "\n",
      "    accuracy                           0.73    226337\n",
      "   macro avg       0.60      0.62      0.61    226337\n",
      "weighted avg       0.75      0.73      0.74    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82    180599\n",
      "           1       0.36      0.45      0.40     45737\n",
      "\n",
      "    accuracy                           0.73    226336\n",
      "   macro avg       0.60      0.62      0.61    226336\n",
      "weighted avg       0.75      0.73      0.74    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.80      0.82    180599\n",
      "           1       0.36      0.45      0.40     45737\n",
      "\n",
      "    accuracy                           0.73    226336\n",
      "   macro avg       0.61      0.62      0.61    226336\n",
      "weighted avg       0.75      0.73      0.74    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.79      0.82    180599\n",
      "           1       0.36      0.45      0.40     45737\n",
      "\n",
      "    accuracy                           0.72    226336\n",
      "   macro avg       0.60      0.62      0.61    226336\n",
      "weighted avg       0.75      0.72      0.74    226336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(shuffle=True, random_state=30)\n",
    "roelst_Ridge = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_X, df_y)):\n",
    "    # 인덱스를 사용하여 학습 및 테스트 데이터를 추출\n",
    "    X_train_fold = df_X.iloc[train_index]\n",
    "    y_train_fold = df_y.iloc[train_index]\n",
    "    X_test_fold = df_X.iloc[test_index]\n",
    "    y_test_fold = df_y.iloc[test_index]\n",
    "\n",
    "    # SMOTE 오버샘플링\n",
    "    smote = SMOTE(random_state=30)\n",
    "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # RidgeClassifierCV 학습\n",
    "    clfRidge_fold = RidgeClassifierCV().fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Test Error:')\n",
    "    y_pred = clfRidge_fold.predict(X_test_fold)\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "\n",
    "    origin_test_df = df.iloc[test_index]\n",
    "\n",
    "    # ROE 계산 및 추가\n",
    "    origin_test_df['y_pred'] = y_pred\n",
    "    roelst_Ridge.append(my_custom_roe(origin_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.044635060039317, 1.0440141923165451, 1.0451849616801596, 1.0450393229329094, 1.0450124921987727]\n",
      "1.0447772058335407\n"
     ]
    }
   ],
   "source": [
    "print(roelst_Ridge)\n",
    "ROE_Ridge = np.mean(roelst_Ridge)\n",
    "print(ROE_Ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88    180600\n",
      "           1       0.43      0.16      0.23     45737\n",
      "\n",
      "    accuracy                           0.79    226337\n",
      "   macro avg       0.62      0.55      0.56    226337\n",
      "weighted avg       0.74      0.79      0.75    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88    180600\n",
      "           1       0.43      0.16      0.24     45737\n",
      "\n",
      "    accuracy                           0.79    226337\n",
      "   macro avg       0.62      0.55      0.56    226337\n",
      "weighted avg       0.74      0.79      0.75    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88    180599\n",
      "           1       0.43      0.16      0.24     45737\n",
      "\n",
      "    accuracy                           0.79    226336\n",
      "   macro avg       0.62      0.55      0.56    226336\n",
      "weighted avg       0.74      0.79      0.75    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88    180599\n",
      "           1       0.44      0.16      0.24     45737\n",
      "\n",
      "    accuracy                           0.79    226336\n",
      "   macro avg       0.63      0.56      0.56    226336\n",
      "weighted avg       0.74      0.79      0.75    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.95      0.88    180599\n",
      "           1       0.43      0.16      0.24     45737\n",
      "\n",
      "    accuracy                           0.79    226336\n",
      "   macro avg       0.62      0.55      0.56    226336\n",
      "weighted avg       0.74      0.79      0.75    226336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(shuffle=True, random_state=30)\n",
    "roelst_RF = []\n",
    "RF_para = {'max_depth':[5, 10, None], \n",
    "           'n_estimators':[15, 30]}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_X, df_y)):\n",
    "    # 인덱스를 사용하여 학습 및 테스트 데이터를 추출\n",
    "    X_train_fold = df_X.iloc[train_index]\n",
    "    y_train_fold = df_y.iloc[train_index]\n",
    "    X_test_fold = df_X.iloc[test_index]\n",
    "    y_test_fold = df_y.iloc[test_index]\n",
    "\n",
    "    # SMOTE 오버샘플링\n",
    "    smote = SMOTE(random_state=30)\n",
    "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Random Forest 학습 \n",
    "    clfRF_fold = RandomForestClassifier(random_state = 30)\n",
    "    clfRF_grid = GridSearchCV(clfRF_fold, RF_para, cv = 5, refit = True)\n",
    "    clfRF_grid.fit(X_train_fold, y_train_fold)\n",
    "    clfRF_fold = clfRF_grid.best_estimator_\n",
    "\n",
    "    print('Test Error:')\n",
    "    y_pred = clfRF_fold.predict(X_test_fold)\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "\n",
    "    origin_test_df = df.iloc[test_index]\n",
    "\n",
    "    # ROE 계산 및 추가\n",
    "    origin_test_df['y_pred'] = y_pred\n",
    "    roelst_RF.append(my_custom_roe(origin_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0396726753183139, 1.039555335000076, 1.0408513802500143, 1.040219273108219, 1.0410321772136437]\n",
      "1.0402661681780532\n"
     ]
    }
   ],
   "source": [
    "print(roelst_RF)\n",
    "ROE_RF = np.mean(roelst_RF)\n",
    "print(ROE_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    180600\n",
      "           1       0.55      0.10      0.17     45737\n",
      "\n",
      "    accuracy                           0.80    226337\n",
      "   macro avg       0.68      0.54      0.53    226337\n",
      "weighted avg       0.76      0.80      0.74    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    180600\n",
      "           1       0.55      0.10      0.17     45737\n",
      "\n",
      "    accuracy                           0.80    226337\n",
      "   macro avg       0.68      0.54      0.53    226337\n",
      "weighted avg       0.76      0.80      0.74    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    180599\n",
      "           1       0.55      0.10      0.17     45737\n",
      "\n",
      "    accuracy                           0.80    226336\n",
      "   macro avg       0.68      0.54      0.53    226336\n",
      "weighted avg       0.76      0.80      0.74    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    180599\n",
      "           1       0.54      0.10      0.17     45737\n",
      "\n",
      "    accuracy                           0.80    226336\n",
      "   macro avg       0.68      0.54      0.53    226336\n",
      "weighted avg       0.76      0.80      0.74    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89    180599\n",
      "           1       0.54      0.10      0.17     45737\n",
      "\n",
      "    accuracy                           0.80    226336\n",
      "   macro avg       0.68      0.54      0.53    226336\n",
      "weighted avg       0.76      0.80      0.74    226336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(shuffle=True, random_state=30)\n",
    "roelst_xgB = []\n",
    "xgB_para = {'n_estimators' : [100, None], \n",
    "           'max_depth' : [15, None],\n",
    "           'gamma' : [0, 1],\n",
    "           'colsample_bytree' : [0.8, 0.9]}\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_X, df_y)):\n",
    "    # 인덱스를 사용하여 학습 및 테스트 데이터를 추출\n",
    "    X_train_fold = df_X.iloc[train_index]\n",
    "    y_train_fold = df_y.iloc[train_index]\n",
    "    X_test_fold = df_X.iloc[test_index]\n",
    "    y_test_fold = df_y.iloc[test_index]\n",
    "\n",
    "    # SMOTE 오버샘플링\n",
    "    smote = SMOTE(random_state=30)\n",
    "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # Random Forest 학습 \n",
    "    clfxgB_fold = XGBClassifier(seed = 30)\n",
    "    clfxgB_grid = GridSearchCV(clfxgB_fold, xgB_para, cv = 5, refit = True)\n",
    "    clfxgB_grid.fit(X_train_fold, y_train_fold)\n",
    "    clfxgB_fold = clfxgB_grid.best_estimator_\n",
    "\n",
    "    print('Test Error:')\n",
    "    y_pred = clfxgB_fold.predict(X_test_fold)\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "\n",
    "    origin_test_df = df.iloc[test_index]\n",
    "\n",
    "    # ROE 계산 및 추가\n",
    "    origin_test_df['y_pred'] = y_pred\n",
    "    roelst_xgB.append(my_custom_roe(origin_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0400145732068389, 1.0397745231418913, 1.041344576153326, 1.0399808720841184, 1.0408086368831841]\n",
      "1.0403846362938718\n"
     ]
    }
   ],
   "source": [
    "print(roelst_xgB)\n",
    "ROE_xgB = np.mean(roelst_xgB)\n",
    "print(ROE_xgB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84    180600\n",
      "           1       0.31      0.25      0.28     45737\n",
      "\n",
      "    accuracy                           0.74    226337\n",
      "   macro avg       0.56      0.55      0.56    226337\n",
      "weighted avg       0.72      0.74      0.72    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.84    180600\n",
      "           1       0.31      0.26      0.28     45737\n",
      "\n",
      "    accuracy                           0.73    226337\n",
      "   macro avg       0.56      0.56      0.56    226337\n",
      "weighted avg       0.72      0.73      0.72    226337\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.86      0.84    180599\n",
      "           1       0.31      0.25      0.28     45737\n",
      "\n",
      "    accuracy                           0.74    226336\n",
      "   macro avg       0.57      0.55      0.56    226336\n",
      "weighted avg       0.72      0.74      0.73    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84    180599\n",
      "           1       0.30      0.22      0.26     45737\n",
      "\n",
      "    accuracy                           0.74    226336\n",
      "   macro avg       0.56      0.55      0.55    226336\n",
      "weighted avg       0.71      0.74      0.72    226336\n",
      "\n",
      "Test Error:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83    180599\n",
      "           1       0.31      0.27      0.29     45737\n",
      "\n",
      "    accuracy                           0.73    226336\n",
      "   macro avg       0.56      0.56      0.56    226336\n",
      "weighted avg       0.72      0.73      0.72    226336\n",
      "\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(shuffle=True, random_state=30)\n",
    "roelst_qda = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(skf.split(df_X, df_y)):\n",
    "    # 인덱스를 사용하여 학습 및 테스트 데이터를 추출\n",
    "    X_train_fold = df_X.iloc[train_index]\n",
    "    y_train_fold = df_y.iloc[train_index]\n",
    "    X_test_fold = df_X.iloc[test_index]\n",
    "    y_test_fold = df_y.iloc[test_index]\n",
    "\n",
    "    # SMOTE 오버샘플링\n",
    "    smote = SMOTE(random_state=30)\n",
    "    X_train_fold, y_train_fold = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "\n",
    "    # RidgeClassifierCV 학습\n",
    "    clfQDA_fold = QDA().fit(X_train_fold, y_train_fold)\n",
    "\n",
    "    print('Test Error:')\n",
    "    y_pred = clfQDA_fold.predict(X_test_fold)\n",
    "    print(classification_report(y_test_fold, y_pred))\n",
    "\n",
    "    origin_test_df = df.iloc[test_index]\n",
    "\n",
    "    # ROE 계산 및 추가\n",
    "    origin_test_df['y_pred'] = y_pred\n",
    "    roelst_qda.append(my_custom_roe(origin_test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0448992145128417, 1.0451616186205173, 1.045871315992722, 1.0442149659778939, 1.0468134887794411]\n",
      "1.045392120776683\n"
     ]
    }
   ],
   "source": [
    "print(roelst_qda)\n",
    "ROE_QDA = np.mean(roelst_qda)\n",
    "print(ROE_QDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
