{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from typing import Union, List\n",
    "import joblib\n",
    "import imblearn\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "#warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modified_0420.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1131682, 26)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#df = p.get_df()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scdf = scaler.fit_transform(df)\n",
    "scdf = pd.DataFrame(scdf)\n",
    "scdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def scaling_data(\n",
    "            self,\n",
    "            scaler:MinMaxScaler|StandardScaler=StandardScaler,\n",
    "            threshold:float=0.95,\n",
    "            over_sampler:SMOTE=None, #RandomOverSampler\n",
    "            under_sampler:TomekLinks=None)->None:\n",
    "        x_scaled = scaler().fit_transform(self.x_train)\n",
    "        self.input_dim = self.__get_n_components_from_pca(x_scaled, threshold=threshold)\n",
    "        self.model_name+=('scaler:'+scaler.__name__+'_pca:'+str(int(threshold*100))+'_input:'+str(self.input_dim))\n",
    "        self.x_train = PCA(n_components=self.input_dim).fit_transform(x_scaled).astype('float32')\n",
    "        if over_sampler!=None:\n",
    "            os = over_sampler(random_state=30)\n",
    "            self.x_train, self.y_train = os.fit_resample(self.x_train,self.y_train)\n",
    "            self.model_name+='_sampler:'+os.__class__.__name__\n",
    "            print(f\"====Data set resampled(oversampled)_{os.__class__.__name__}\")\n",
    "        elif under_sampler!=None:\n",
    "            us = under_sampler(random_state=30, sampling_strategy='majority')\n",
    "            self.x_train, self.y_train = us.fit_resample(self.x_train, self.y_train)\n",
    "            self.model_name+='_sampler:'+us.__class__.__name__\n",
    "            print(f\"====Data set resampled(undersampled)_{us.__class__.__name__}\")\n",
    "        print(f\"==label ratio\")\n",
    "        print(f\"True Label:\\t{np.sum(self.y_train==1)/len(self.y_train)}\")\n",
    "        print(f\"False Label:\\t{np.sum(self.y_train==0)/len(self.y_train)}\")\n",
    "        self.x_train, self.x_validation, self.y_train, self.y_validation = train_test_split(self.x_train, self.y_train, test_size=0.2, stratify=self.y_train, random_state=30)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
