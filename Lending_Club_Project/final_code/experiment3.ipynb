{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from typing import Union, List\n",
    "import joblib\n",
    "import imblearn\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "#warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('modified_log_var25_0426.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1131682, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_util_log</th>\n",
       "      <th>annual_inc_log</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt_log</th>\n",
       "      <th>dti_log</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>fico_avg</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>is_after_2012</th>\n",
       "      <th>is_after_2015</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>term</th>\n",
       "      <th>tot_cur_bal_log</th>\n",
       "      <th>total_acc_log</th>\n",
       "      <th>total_bc_limit_log</th>\n",
       "      <th>MORTGAGE</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>OWN</th>\n",
       "      <th>RENT</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.174387</td>\n",
       "      <td>10.714440</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.269028</td>\n",
       "      <td>2</td>\n",
       "      <td>757.0</td>\n",
       "      <td>7.97</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>36</td>\n",
       "      <td>10.820878</td>\n",
       "      <td>3.610918</td>\n",
       "      <td>9.615872</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.454347</td>\n",
       "      <td>11.608245</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.575151</td>\n",
       "      <td>10</td>\n",
       "      <td>672.0</td>\n",
       "      <td>24.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>60</td>\n",
       "      <td>13.315176</td>\n",
       "      <td>4.110874</td>\n",
       "      <td>9.918425</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.332205</td>\n",
       "      <td>11.082158</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.930660</td>\n",
       "      <td>10</td>\n",
       "      <td>822.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>11.522113</td>\n",
       "      <td>3.367296</td>\n",
       "      <td>10.987003</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.637586</td>\n",
       "      <td>10.819798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.078191</td>\n",
       "      <td>5</td>\n",
       "      <td>702.0</td>\n",
       "      <td>10.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>12.178635</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>9.137877</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.002116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.399195</td>\n",
       "      <td>10</td>\n",
       "      <td>677.0</td>\n",
       "      <td>9.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>11.831590</td>\n",
       "      <td>3.713572</td>\n",
       "      <td>9.305741</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131677</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.002116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.045474</td>\n",
       "      <td>2</td>\n",
       "      <td>697.0</td>\n",
       "      <td>17.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>12.346938</td>\n",
       "      <td>2.833213</td>\n",
       "      <td>9.846970</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131678</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.428246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.004692</td>\n",
       "      <td>7</td>\n",
       "      <td>667.0</td>\n",
       "      <td>19.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>36</td>\n",
       "      <td>11.195760</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>8.779711</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131679</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.170449</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.215671</td>\n",
       "      <td>4</td>\n",
       "      <td>737.0</td>\n",
       "      <td>6.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>12.388636</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>9.775711</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131680</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.691968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.628285</td>\n",
       "      <td>9</td>\n",
       "      <td>692.0</td>\n",
       "      <td>14.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>11.884551</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>8.343078</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131681</th>\n",
       "      <td>3.218876</td>\n",
       "      <td>11.112463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.088312</td>\n",
       "      <td>5</td>\n",
       "      <td>737.0</td>\n",
       "      <td>7.35</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>36</td>\n",
       "      <td>12.243108</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>11.604602</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1131682 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         all_util_log  annual_inc_log  chargeoff_within_12_mths  \\\n",
       "0            4.174387       10.714440                       0.0   \n",
       "1            4.454347       11.608245                       0.0   \n",
       "2            3.332205       11.082158                       0.0   \n",
       "3            3.637586       10.819798                       0.0   \n",
       "4            0.000000       11.002116                       0.0   \n",
       "...               ...             ...                       ...   \n",
       "1131677      0.000000       11.002116                       0.0   \n",
       "1131678      0.000000       10.428246                       0.0   \n",
       "1131679      0.000000       11.170449                       0.0   \n",
       "1131680      0.000000       10.691968                       0.0   \n",
       "1131681      3.218876       11.112463                       0.0   \n",
       "\n",
       "         delinq_amnt_log   dti_log  emp_length  fico_avg  int_rate  \\\n",
       "0                    0.0  2.269028           2     757.0      7.97   \n",
       "1                    0.0  3.575151          10     672.0     24.99   \n",
       "2                    0.0  2.930660          10     822.0      7.07   \n",
       "3                    0.0  2.078191           5     702.0     10.42   \n",
       "4                    0.0  3.399195          10     677.0      9.99   \n",
       "...                  ...       ...         ...       ...       ...   \n",
       "1131677              0.0  3.045474           2     697.0     17.27   \n",
       "1131678              0.0  3.004692           7     667.0     19.99   \n",
       "1131679              0.0  3.215671           4     737.0      6.68   \n",
       "1131680              0.0  2.628285           9     692.0     14.33   \n",
       "1131681              0.0  3.088312           5     737.0      7.35   \n",
       "\n",
       "         is_after_2012  is_after_2015  ...  sub_grade  term  tot_cur_bal_log  \\\n",
       "0                    1              1  ...          4    36        10.820878   \n",
       "1                    1              1  ...         23    60        13.315176   \n",
       "2                    1              1  ...          1    36        11.522113   \n",
       "3                    1              1  ...          7    36        12.178635   \n",
       "4                    1              0  ...          7    36        11.831590   \n",
       "...                ...            ...  ...        ...   ...              ...   \n",
       "1131677              1              0  ...         14    60        12.346938   \n",
       "1131678              1              0  ...         20    36        11.195760   \n",
       "1131679              1              0  ...          2    36        12.388636   \n",
       "1131680              1              0  ...         10    36        11.884551   \n",
       "1131681              1              1  ...          3    36        12.243108   \n",
       "\n",
       "         total_acc_log  total_bc_limit_log  MORTGAGE  OTHERS    OWN   RENT  \\\n",
       "0             3.610918            9.615872      True   False  False  False   \n",
       "1             4.110874            9.918425      True   False  False  False   \n",
       "2             3.367296           10.987003      True   False  False  False   \n",
       "3             2.302585            9.137877      True   False  False  False   \n",
       "4             3.713572            9.305741      True   False  False  False   \n",
       "...                ...                 ...       ...     ...    ...    ...   \n",
       "1131677       2.833213            9.846970      True   False  False  False   \n",
       "1131678       2.302585            8.779711      True   False  False  False   \n",
       "1131679       3.526361            9.775711      True   False  False  False   \n",
       "1131680       2.197225            8.343078      True   False  False  False   \n",
       "1131681       3.583519           11.604602      True   False  False  False   \n",
       "\n",
       "         verification_status  \n",
       "0                          0  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          0  \n",
       "...                      ...  \n",
       "1131677                    0  \n",
       "1131678                    1  \n",
       "1131679                    1  \n",
       "1131680                    0  \n",
       "1131681                    0  \n",
       "\n",
       "[1131682 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = p.get_df()\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df)\n",
    "scaled_df = pd.DataFrame(scaler.transform(df), index = df.index, columns = df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>all_util_log</th>\n",
       "      <th>annual_inc_log</th>\n",
       "      <th>chargeoff_within_12_mths</th>\n",
       "      <th>delinq_amnt_log</th>\n",
       "      <th>dti_log</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>fico_avg</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>is_after_2012</th>\n",
       "      <th>is_after_2015</th>\n",
       "      <th>...</th>\n",
       "      <th>sub_grade</th>\n",
       "      <th>term</th>\n",
       "      <th>tot_cur_bal_log</th>\n",
       "      <th>total_acc_log</th>\n",
       "      <th>total_bc_limit_log</th>\n",
       "      <th>MORTGAGE</th>\n",
       "      <th>OTHERS</th>\n",
       "      <th>OWN</th>\n",
       "      <th>RENT</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.788616</td>\n",
       "      <td>0.578659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328475</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.512129</td>\n",
       "      <td>0.103583</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.697662</td>\n",
       "      <td>0.622291</td>\n",
       "      <td>0.691673</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.841506</td>\n",
       "      <td>0.626931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517556</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.053908</td>\n",
       "      <td>0.766355</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.858478</td>\n",
       "      <td>0.746129</td>\n",
       "      <td>0.713436</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.629513</td>\n",
       "      <td>0.598518</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.424257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.862534</td>\n",
       "      <td>0.068536</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742873</td>\n",
       "      <td>0.561947</td>\n",
       "      <td>0.790299</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.687205</td>\n",
       "      <td>0.584349</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300849</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.215633</td>\n",
       "      <td>0.198988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785201</td>\n",
       "      <td>0.298221</td>\n",
       "      <td>0.657291</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.492084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.080863</td>\n",
       "      <td>0.182243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.205882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.762826</td>\n",
       "      <td>0.647718</td>\n",
       "      <td>0.669366</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131677</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.594195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.440878</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.188679</td>\n",
       "      <td>0.465732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.796052</td>\n",
       "      <td>0.429656</td>\n",
       "      <td>0.708296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131678</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.563202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434974</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.026954</td>\n",
       "      <td>0.571651</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.721832</td>\n",
       "      <td>0.298221</td>\n",
       "      <td>0.631528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131679</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.603287</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465516</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.404313</td>\n",
       "      <td>0.053349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.798741</td>\n",
       "      <td>0.601347</td>\n",
       "      <td>0.703171</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131680</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380483</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.161725</td>\n",
       "      <td>0.351246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.766240</td>\n",
       "      <td>0.272123</td>\n",
       "      <td>0.600121</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1131681</th>\n",
       "      <td>0.608103</td>\n",
       "      <td>0.600155</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447079</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.404313</td>\n",
       "      <td>0.079439</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.789358</td>\n",
       "      <td>0.615505</td>\n",
       "      <td>0.834723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1131682 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         all_util_log  annual_inc_log  chargeoff_within_12_mths  \\\n",
       "0            0.788616        0.578659                       0.0   \n",
       "1            0.841506        0.626931                       0.0   \n",
       "2            0.629513        0.598518                       0.0   \n",
       "3            0.687205        0.584349                       0.0   \n",
       "4            0.000000        0.594195                       0.0   \n",
       "...               ...             ...                       ...   \n",
       "1131677      0.000000        0.594195                       0.0   \n",
       "1131678      0.000000        0.563202                       0.0   \n",
       "1131679      0.000000        0.603287                       0.0   \n",
       "1131680      0.000000        0.577445                       0.0   \n",
       "1131681      0.608103        0.600155                       0.0   \n",
       "\n",
       "         delinq_amnt_log   dti_log  emp_length  fico_avg  int_rate  \\\n",
       "0                    0.0  0.328475         0.2  0.512129  0.103583   \n",
       "1                    0.0  0.517556         1.0  0.053908  0.766355   \n",
       "2                    0.0  0.424257         1.0  0.862534  0.068536   \n",
       "3                    0.0  0.300849         0.5  0.215633  0.198988   \n",
       "4                    0.0  0.492084         1.0  0.080863  0.182243   \n",
       "...                  ...       ...         ...       ...       ...   \n",
       "1131677              0.0  0.440878         0.2  0.188679  0.465732   \n",
       "1131678              0.0  0.434974         0.7  0.026954  0.571651   \n",
       "1131679              0.0  0.465516         0.4  0.404313  0.053349   \n",
       "1131680              0.0  0.380483         0.9  0.161725  0.351246   \n",
       "1131681              0.0  0.447079         0.5  0.404313  0.079439   \n",
       "\n",
       "         is_after_2012  is_after_2015  ...  sub_grade  term  tot_cur_bal_log  \\\n",
       "0                  1.0            1.0  ...   0.117647   0.0         0.697662   \n",
       "1                  1.0            1.0  ...   0.676471   1.0         0.858478   \n",
       "2                  1.0            1.0  ...   0.029412   0.0         0.742873   \n",
       "3                  1.0            1.0  ...   0.205882   0.0         0.785201   \n",
       "4                  1.0            0.0  ...   0.205882   0.0         0.762826   \n",
       "...                ...            ...  ...        ...   ...              ...   \n",
       "1131677            1.0            0.0  ...   0.411765   1.0         0.796052   \n",
       "1131678            1.0            0.0  ...   0.588235   0.0         0.721832   \n",
       "1131679            1.0            0.0  ...   0.058824   0.0         0.798741   \n",
       "1131680            1.0            0.0  ...   0.294118   0.0         0.766240   \n",
       "1131681            1.0            1.0  ...   0.088235   0.0         0.789358   \n",
       "\n",
       "         total_acc_log  total_bc_limit_log  MORTGAGE  OTHERS  OWN  RENT  \\\n",
       "0             0.622291            0.691673       1.0     0.0  0.0   0.0   \n",
       "1             0.746129            0.713436       1.0     0.0  0.0   0.0   \n",
       "2             0.561947            0.790299       1.0     0.0  0.0   0.0   \n",
       "3             0.298221            0.657291       1.0     0.0  0.0   0.0   \n",
       "4             0.647718            0.669366       1.0     0.0  0.0   0.0   \n",
       "...                ...                 ...       ...     ...  ...   ...   \n",
       "1131677       0.429656            0.708296       1.0     0.0  0.0   0.0   \n",
       "1131678       0.298221            0.631528       1.0     0.0  0.0   0.0   \n",
       "1131679       0.601347            0.703171       1.0     0.0  0.0   0.0   \n",
       "1131680       0.272123            0.600121       1.0     0.0  0.0   0.0   \n",
       "1131681       0.615505            0.834723       1.0     0.0  0.0   0.0   \n",
       "\n",
       "         verification_status  \n",
       "0                        0.0  \n",
       "1                        0.0  \n",
       "2                        1.0  \n",
       "3                        1.0  \n",
       "4                        0.0  \n",
       "...                      ...  \n",
       "1131677                  0.0  \n",
       "1131678                  1.0  \n",
       "1131679                  1.0  \n",
       "1131680                  0.0  \n",
       "1131681                  0.0  \n",
       "\n",
       "[1131682 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X = scaled_df.drop(columns=['loan_status'])\n",
    "df_y = scaled_df['loan_status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size = 0.2, random_state = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#smote oversample\n",
    "smote = SMOTE(random_state = 30)\n",
    "\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RidgeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRidge = RidgeClassifierCV().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.88      0.66      0.75    180654\n",
      "         1.0       0.32      0.65      0.43     45683\n",
      "\n",
      "    accuracy                           0.66    226337\n",
      "   macro avg       0.60      0.65      0.59    226337\n",
      "weighted avg       0.77      0.66      0.69    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfRidge.predict(X_test)\n",
    "joblib.dump(clfRidge, 'clfRidge_3.pkl')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.roc_curve.RocCurveDisplay at 0x2019d891ca0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr = fpr, tpr = tpr, roc_auc = roc_auc, estimator_name='clfRidge')\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LassoClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clfLasso = LogisticRegressionCV(penalty='l1', solver = 'saga').fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.98      0.89    180654\n",
      "         1.0       0.54      0.09      0.15     45683\n",
      "\n",
      "    accuracy                           0.80    226337\n",
      "   macro avg       0.68      0.53      0.52    226337\n",
      "weighted avg       0.76      0.80      0.74    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clfLasso.predict(X_test)\n",
    "joblib.dump(clfLasso, 'clfLasso_3.pkl')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr = fpr, tpr = tpr, roc_auc = roc_auc, estimator_name='pcaRF')\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[24], line 2\u001b[0m\n",
      "\u001b[0;32m      1\u001b[0m clfRF \u001b[38;5;241m=\u001b[39m RandomForestClassifier(max_depth \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m)\n",
      "\u001b[1;32m----> 2\u001b[0m \u001b[43mclfRF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n",
      "\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n",
      "\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n",
      "\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n",
      "\u001b[0;32m   1472\u001b[0m     )\n",
      "\u001b[0;32m   1473\u001b[0m ):\n",
      "\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n",
      "\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n",
      "\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n",
      "\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n",
      "\u001b[0;32m    481\u001b[0m ]\n",
      "\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n",
      "\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n",
      "\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n",
      "\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n",
      "\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n",
      "\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n",
      "\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n",
      "\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n",
      "\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n",
      "\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n",
      "\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n",
      "\u001b[0;32m     66\u001b[0m )\n",
      "\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n",
      "\u001b[0;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n",
      "\u001b[1;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n",
      "\u001b[0;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n",
      "\u001b[0;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n",
      "\u001b[0;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n",
      "\u001b[0;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n",
      "\u001b[0;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n",
      "\u001b[0;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n",
      "\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n",
      "\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n",
      "\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n",
      "\u001b[0;32m    201\u001b[0m         X,\n",
      "\u001b[0;32m    202\u001b[0m         y,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n",
      "\u001b[0;32m    206\u001b[0m     )\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\Na\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n",
      "\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n",
      "\u001b[0;32m    463\u001b[0m         splitter,\n",
      "\u001b[0;32m    464\u001b[0m         min_samples_split,\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n",
      "\u001b[0;32m    470\u001b[0m     )\n",
      "\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clfRF = RandomForestClassifier(max_depth = 30, random_state = 30)\n",
    "clfRF.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.99      0.89    180654\n",
      "         1.0       0.56      0.07      0.12     45683\n",
      "\n",
      "    accuracy                           0.80    226337\n",
      "   macro avg       0.68      0.53      0.50    226337\n",
      "weighted avg       0.76      0.80      0.73    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clfRF.predict(X_test)\n",
    "joblib.dump(clfRF, 'clfRF_3.pkl')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr = fpr, tpr = tpr, roc_auc = roc_auc, estimator_name='pcaRF')\n",
    "display.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-6 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-6 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-6 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-6 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-6 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-6 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-6 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-6 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-6 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-6 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=30, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=30, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=30, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=None, ...)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfXGB = XGBClassifier(random_state = 30, max_depth = 30)\n",
    "clfXGB.fit(X_train, y_train)\n",
    "clfXGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.97      0.88    180654\n",
      "         1.0       0.48      0.13      0.20     45683\n",
      "\n",
      "    accuracy                           0.80    226337\n",
      "   macro avg       0.65      0.55      0.54    226337\n",
      "weighted avg       0.75      0.80      0.75    226337\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clfXGB.predict(X_test)\n",
    "joblib.dump(clfXGB, 'clfXGB_3.pkl')\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "display = metrics.RocCurveDisplay(fpr = fpr, tpr = tpr, roc_auc = roc_auc, estimator_name='pcaRF')\n",
    "display.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
